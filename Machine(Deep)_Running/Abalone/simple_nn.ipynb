{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ababbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c706ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "test.drop('id', axis=1, inplace=True)\n",
    "\n",
    "train_X = train.drop('Target', axis=1)\n",
    "train_y = train.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf096a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.get_dummies(data = train_X, columns = ['Gender'], prefix = 'Gender')\n",
    "test = pd.get_dummies(data = test, columns = ['Gender'], prefix = 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e411461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscra Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_I</th>\n",
       "      <th>Gender_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1.1140</td>\n",
       "      <td>0.3925</td>\n",
       "      <td>0.2910</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.430</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.3165</td>\n",
       "      <td>0.5305</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2705</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.3265</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>0.190</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.8325</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lenght  Diameter  Height  Whole Weight  Shucked Weight  Viscra Weight  \\\n",
       "0      0.605     0.470   0.115        1.1140          0.3925         0.2910   \n",
       "1      0.430     0.315   0.095        0.3780          0.1750         0.0800   \n",
       "2      0.580     0.490   0.195        1.3165          0.5305         0.2540   \n",
       "3      0.535     0.405   0.175        1.2705          0.5480         0.3265   \n",
       "4      0.310     0.235   0.090        0.1270          0.0480         0.0310   \n",
       "...      ...       ...     ...           ...             ...            ...   \n",
       "1248   0.190     0.145   0.040        0.0380          0.0165         0.0065   \n",
       "1249   0.395     0.310   0.085        0.3170          0.1530         0.0505   \n",
       "1250   0.525     0.410   0.115        0.7745          0.4160         0.1630   \n",
       "1251   0.445     0.335   0.110        0.4355          0.2025         0.1095   \n",
       "1252   0.750     0.550   0.195        1.8325          0.8300         0.3660   \n",
       "\n",
       "      Shell Weight  Gender_F  Gender_I  Gender_M  \n",
       "0           0.3100         0         0         1  \n",
       "1           0.1045         0         1         0  \n",
       "2           0.4100         0         1         0  \n",
       "3           0.3370         0         0         1  \n",
       "4           0.0400         0         1         0  \n",
       "...            ...       ...       ...       ...  \n",
       "1248        0.0150         0         1         0  \n",
       "1249        0.0935         0         1         0  \n",
       "1250        0.1800         1         0         0  \n",
       "1251        0.1195         1         0         0  \n",
       "1252        0.4400         1         0         0  \n",
       "\n",
       "[1253 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b80bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전복 전체 무게 대비 불필요한 물질들의 값 ( 이물질 / 핏물 등)\n",
    "foreign_body = train_X['Whole Weight'] - (train_X['Shucked Weight'] + train_X['Viscra Weight'] + train_X['Shell Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ebaae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.1205\n",
       "1       0.0185\n",
       "2       0.1220\n",
       "3       0.0590\n",
       "4       0.0080\n",
       "         ...  \n",
       "1248    0.0000\n",
       "1249    0.0200\n",
       "1250    0.0155\n",
       "1251    0.0040\n",
       "1252    0.1965\n",
       "Length: 1253, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreign_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1313c952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06749999999999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foreign_body[47]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ae77369",
   "metadata": {},
   "source": [
    "전체 무게가 살 + 내장 + 껍질보다 적게나갈 경우???   \n",
    "    \n",
    "전체 무게 - (살 + 내장 + 껍질)  = 핏물 + 껍데기 물 이물질 \n",
    "\n",
    "전체 무게 - (살 + 내장 + 껍질) > 0 => 핏물 껍데기 물이 있다\n",
    "\n",
    "전체 무게 - (살 + 내장 + 껍질) < 0 => 핏물 껍데기 물이 없다??? => 말이 안됨 => 0으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "840492ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X['foreign body'] = foreign_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a2c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc[train_X['foreign body'] < 0 , 'foreign body'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c93b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋에도 적용\n",
    "foreign_body = test['Whole Weight'] - (test['Shucked Weight'] + test['Viscra Weight'] + test['Shell Weight'])\n",
    "test['foreign body'] = foreign_body\n",
    "test.loc[test['foreign body'] < 0 , 'foreign body'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747231f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7719a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22b73e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=11, activation='elu'))\n",
    "model.add(Dense(32,  activation='elu'))    \n",
    "model.add(Dense(64, activation='elu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(Dense(16, activation='elu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "              optimizer='Nadam', \n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33e4377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = MODEL_DIR + \"{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "cp = ModelCheckpoint(filepath=modelpath, monitor='val_mae', verbose=0, save_best_only=True, mode = 'min')\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "es = EarlyStopping(monitor='val_mae', patience=50, mode='min')\n",
    "\n",
    "rlrp = ReduceLROnPlateau(monitor='val_mae', factor=0.2, patience=40, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b455104f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 6.0501 - mae: 6.0501 - val_loss: 2.1513 - val_mae: 2.1513 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.2264 - mae: 2.2264 - val_loss: 1.9263 - val_mae: 1.9263 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.1204 - mae: 2.1204 - val_loss: 1.9531 - val_mae: 1.9531 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.9960 - mae: 1.9960 - val_loss: 1.8990 - val_mae: 1.8990 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 2.0176 - mae: 2.0176 - val_loss: 1.8963 - val_mae: 1.8963 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.9007 - mae: 1.9007 - val_loss: 1.9110 - val_mae: 1.9110 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.9039 - mae: 1.9039 - val_loss: 1.9011 - val_mae: 1.9011 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.8508 - mae: 1.8508 - val_loss: 1.9129 - val_mae: 1.9129 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.8423 - mae: 1.8423 - val_loss: 1.8817 - val_mae: 1.8817 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.8658 - mae: 1.8658 - val_loss: 1.9175 - val_mae: 1.9175 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7801 - mae: 1.7801 - val_loss: 1.9149 - val_mae: 1.9149 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7722 - mae: 1.7722 - val_loss: 1.8935 - val_mae: 1.8935 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7826 - mae: 1.7826 - val_loss: 1.8581 - val_mae: 1.8581 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7340 - mae: 1.7340 - val_loss: 1.8945 - val_mae: 1.8945 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7540 - mae: 1.7540 - val_loss: 1.8706 - val_mae: 1.8706 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7521 - mae: 1.7521 - val_loss: 1.8419 - val_mae: 1.8419 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.7404 - mae: 1.7404 - val_loss: 1.8335 - val_mae: 1.8335 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7313 - mae: 1.7313 - val_loss: 1.9883 - val_mae: 1.9883 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6892 - mae: 1.6892 - val_loss: 1.8251 - val_mae: 1.8251 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6833 - mae: 1.6833 - val_loss: 1.7848 - val_mae: 1.7848 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6774 - mae: 1.6774 - val_loss: 1.7708 - val_mae: 1.7708 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6738 - mae: 1.6738 - val_loss: 1.8882 - val_mae: 1.8882 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6702 - mae: 1.6702 - val_loss: 2.0211 - val_mae: 2.0211 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6356 - mae: 1.6356 - val_loss: 1.7643 - val_mae: 1.7643 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.6203 - mae: 1.6203 - val_loss: 1.7207 - val_mae: 1.7207 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.5963 - mae: 1.5963 - val_loss: 1.7298 - val_mae: 1.7298 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6153 - mae: 1.6153 - val_loss: 1.7837 - val_mae: 1.7837 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5702 - mae: 1.5702 - val_loss: 1.7112 - val_mae: 1.7112 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5755 - mae: 1.5755 - val_loss: 1.7091 - val_mae: 1.7091 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5682 - mae: 1.5682 - val_loss: 1.6937 - val_mae: 1.6937 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5837 - mae: 1.5837 - val_loss: 1.6832 - val_mae: 1.6832 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5717 - mae: 1.5717 - val_loss: 1.7022 - val_mae: 1.7022 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6104 - mae: 1.6104 - val_loss: 1.6725 - val_mae: 1.6725 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5656 - mae: 1.5656 - val_loss: 1.7052 - val_mae: 1.7052 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 1.5174 - mae: 1.5174 - val_loss: 1.6681 - val_mae: 1.6681 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5599 - mae: 1.5599 - val_loss: 1.9801 - val_mae: 1.9801 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5713 - mae: 1.5713 - val_loss: 1.6815 - val_mae: 1.6815 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5496 - mae: 1.5496 - val_loss: 1.8425 - val_mae: 1.8425 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5285 - mae: 1.5285 - val_loss: 1.9023 - val_mae: 1.9023 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5131 - mae: 1.5131 - val_loss: 1.6937 - val_mae: 1.6937 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5218 - mae: 1.5218 - val_loss: 1.6688 - val_mae: 1.6688 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5512 - mae: 1.5512 - val_loss: 1.6990 - val_mae: 1.6990 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5463 - mae: 1.5463 - val_loss: 1.7036 - val_mae: 1.7036 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5858 - mae: 1.5858 - val_loss: 1.7095 - val_mae: 1.7095 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5627 - mae: 1.5627 - val_loss: 1.6720 - val_mae: 1.6720 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4909 - mae: 1.4909 - val_loss: 1.6884 - val_mae: 1.6884 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5225 - mae: 1.5225 - val_loss: 1.6652 - val_mae: 1.6652 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5274 - mae: 1.5274 - val_loss: 1.6776 - val_mae: 1.6776 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4945 - mae: 1.4945 - val_loss: 1.7103 - val_mae: 1.7103 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5295 - mae: 1.5295 - val_loss: 1.6616 - val_mae: 1.6616 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5182 - mae: 1.5182 - val_loss: 1.7650 - val_mae: 1.7650 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4987 - mae: 1.4987 - val_loss: 1.6795 - val_mae: 1.6795 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5486 - mae: 1.5486 - val_loss: 1.6488 - val_mae: 1.6488 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5333 - mae: 1.5333 - val_loss: 1.7108 - val_mae: 1.7108 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5246 - mae: 1.5246 - val_loss: 1.7227 - val_mae: 1.7227 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5321 - mae: 1.5321 - val_loss: 1.6620 - val_mae: 1.6620 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5381 - mae: 1.5381 - val_loss: 1.6823 - val_mae: 1.6823 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5368 - mae: 1.5368 - val_loss: 1.7188 - val_mae: 1.7188 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5462 - mae: 1.5462 - val_loss: 1.6841 - val_mae: 1.6841 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4880 - mae: 1.4880 - val_loss: 1.7226 - val_mae: 1.7226 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4998 - mae: 1.4998 - val_loss: 1.7357 - val_mae: 1.7357 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5094 - mae: 1.5094 - val_loss: 1.7021 - val_mae: 1.7021 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5066 - mae: 1.5066 - val_loss: 1.6557 - val_mae: 1.6557 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5059 - mae: 1.5059 - val_loss: 1.7095 - val_mae: 1.7095 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4636 - mae: 1.4636 - val_loss: 1.6564 - val_mae: 1.6564 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5012 - mae: 1.5012 - val_loss: 1.7993 - val_mae: 1.7993 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4920 - mae: 1.4920 - val_loss: 1.6451 - val_mae: 1.6451 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4864 - mae: 1.4864 - val_loss: 1.6679 - val_mae: 1.6679 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4830 - mae: 1.4830 - val_loss: 1.6601 - val_mae: 1.6601 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4758 - mae: 1.4758 - val_loss: 1.6881 - val_mae: 1.6881 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5031 - mae: 1.5031 - val_loss: 1.6413 - val_mae: 1.6413 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4935 - mae: 1.4935 - val_loss: 1.6336 - val_mae: 1.6336 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4929 - mae: 1.4929 - val_loss: 1.7003 - val_mae: 1.7003 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4905 - mae: 1.4905 - val_loss: 1.6229 - val_mae: 1.6229 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4861 - mae: 1.4861 - val_loss: 1.6276 - val_mae: 1.6276 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4968 - mae: 1.4968 - val_loss: 1.6828 - val_mae: 1.6828 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4763 - mae: 1.4763 - val_loss: 1.6682 - val_mae: 1.6682 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4908 - mae: 1.4908 - val_loss: 1.6479 - val_mae: 1.6479 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5197 - mae: 1.5197 - val_loss: 1.6018 - val_mae: 1.6018 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4860 - mae: 1.4860 - val_loss: 1.6071 - val_mae: 1.6071 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5080 - mae: 1.5080 - val_loss: 1.6603 - val_mae: 1.6603 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4885 - mae: 1.4885 - val_loss: 1.6376 - val_mae: 1.6376 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4954 - mae: 1.4954 - val_loss: 1.6251 - val_mae: 1.6251 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4723 - mae: 1.4723 - val_loss: 1.6326 - val_mae: 1.6326 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4956 - mae: 1.4956 - val_loss: 1.7014 - val_mae: 1.7014 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4554 - mae: 1.4554 - val_loss: 1.6115 - val_mae: 1.6115 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.5008 - mae: 1.5008 - val_loss: 1.5916 - val_mae: 1.5916 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4711 - mae: 1.4711 - val_loss: 1.6088 - val_mae: 1.6088 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5058 - mae: 1.5058 - val_loss: 1.6232 - val_mae: 1.6232 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4831 - mae: 1.4831 - val_loss: 1.6734 - val_mae: 1.6734 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4532 - mae: 1.4532 - val_loss: 1.6257 - val_mae: 1.6257 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4803 - mae: 1.4803 - val_loss: 1.6330 - val_mae: 1.6330 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4714 - mae: 1.4714 - val_loss: 1.6044 - val_mae: 1.6044 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4844 - mae: 1.4844 - val_loss: 1.6130 - val_mae: 1.6130 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4665 - mae: 1.4665 - val_loss: 1.6099 - val_mae: 1.6099 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4742 - mae: 1.4742 - val_loss: 1.6872 - val_mae: 1.6872 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4660 - mae: 1.4660 - val_loss: 1.6863 - val_mae: 1.6863 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4502 - mae: 1.4502 - val_loss: 1.6388 - val_mae: 1.6388 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4533 - mae: 1.4533 - val_loss: 1.5879 - val_mae: 1.5879 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4840 - mae: 1.4840 - val_loss: 1.5922 - val_mae: 1.5922 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4731 - mae: 1.4731 - val_loss: 1.6313 - val_mae: 1.6313 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4594 - mae: 1.4594 - val_loss: 1.5902 - val_mae: 1.5902 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4326 - mae: 1.4326 - val_loss: 1.7110 - val_mae: 1.7110 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4549 - mae: 1.4549 - val_loss: 1.5758 - val_mae: 1.5758 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4676 - mae: 1.4676 - val_loss: 1.6691 - val_mae: 1.6691 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4835 - mae: 1.4835 - val_loss: 1.7028 - val_mae: 1.7028 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4616 - mae: 1.4616 - val_loss: 1.5854 - val_mae: 1.5854 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4556 - mae: 1.4556 - val_loss: 1.5779 - val_mae: 1.5779 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4514 - mae: 1.4514 - val_loss: 1.6094 - val_mae: 1.6094 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4371 - mae: 1.4371 - val_loss: 1.5787 - val_mae: 1.5787 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4542 - mae: 1.4542 - val_loss: 1.5765 - val_mae: 1.5765 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4574 - mae: 1.4574 - val_loss: 1.6174 - val_mae: 1.6174 - lr: 0.0010\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4668 - mae: 1.4668 - val_loss: 1.5902 - val_mae: 1.5902 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4367 - mae: 1.4367 - val_loss: 1.5621 - val_mae: 1.5621 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4776 - mae: 1.4776 - val_loss: 1.5587 - val_mae: 1.5587 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4369 - mae: 1.4369 - val_loss: 1.6057 - val_mae: 1.6057 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4724 - mae: 1.4724 - val_loss: 1.5822 - val_mae: 1.5822 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4472 - mae: 1.4472 - val_loss: 1.6545 - val_mae: 1.6545 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4439 - mae: 1.4439 - val_loss: 1.5754 - val_mae: 1.5754 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4497 - mae: 1.4497 - val_loss: 1.5683 - val_mae: 1.5683 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4573 - mae: 1.4573 - val_loss: 1.5810 - val_mae: 1.5810 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4290 - mae: 1.4290 - val_loss: 1.5868 - val_mae: 1.5868 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4192 - mae: 1.4192 - val_loss: 1.5927 - val_mae: 1.5927 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4416 - mae: 1.4416 - val_loss: 1.5516 - val_mae: 1.5516 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4437 - mae: 1.4437 - val_loss: 1.6177 - val_mae: 1.6177 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4279 - mae: 1.4279 - val_loss: 1.5675 - val_mae: 1.5675 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4475 - mae: 1.4475 - val_loss: 1.6009 - val_mae: 1.6009 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4500 - mae: 1.4500 - val_loss: 1.5949 - val_mae: 1.5949 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4561 - mae: 1.4561 - val_loss: 1.5413 - val_mae: 1.5413 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4405 - mae: 1.4405 - val_loss: 1.6782 - val_mae: 1.6782 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4361 - mae: 1.4361 - val_loss: 1.6085 - val_mae: 1.6085 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4449 - mae: 1.4449 - val_loss: 1.5491 - val_mae: 1.5491 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4547 - mae: 1.4547 - val_loss: 1.5686 - val_mae: 1.5686 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4551 - mae: 1.4551 - val_loss: 1.5749 - val_mae: 1.5749 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4144 - mae: 1.4144 - val_loss: 1.5413 - val_mae: 1.5413 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4250 - mae: 1.4250 - val_loss: 1.5544 - val_mae: 1.5544 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4454 - mae: 1.4454 - val_loss: 1.5789 - val_mae: 1.5789 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4186 - mae: 1.4186 - val_loss: 1.5327 - val_mae: 1.5327 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4203 - mae: 1.4203 - val_loss: 1.5683 - val_mae: 1.5683 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4254 - mae: 1.4254 - val_loss: 1.6037 - val_mae: 1.6037 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4349 - mae: 1.4349 - val_loss: 1.5324 - val_mae: 1.5324 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4061 - mae: 1.4061 - val_loss: 1.5607 - val_mae: 1.5607 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4568 - mae: 1.4568 - val_loss: 1.6478 - val_mae: 1.6478 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4172 - mae: 1.4172 - val_loss: 1.5439 - val_mae: 1.5439 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4345 - mae: 1.4345 - val_loss: 1.5513 - val_mae: 1.5513 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4506 - mae: 1.4506 - val_loss: 1.5569 - val_mae: 1.5569 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4193 - mae: 1.4193 - val_loss: 1.5373 - val_mae: 1.5373 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4242 - mae: 1.4242 - val_loss: 1.5977 - val_mae: 1.5977 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4165 - mae: 1.4165 - val_loss: 1.6012 - val_mae: 1.6012 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4253 - mae: 1.4253 - val_loss: 1.5454 - val_mae: 1.5454 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4113 - mae: 1.4113 - val_loss: 1.7206 - val_mae: 1.7206 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4433 - mae: 1.4433 - val_loss: 1.5480 - val_mae: 1.5480 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4118 - mae: 1.4118 - val_loss: 1.5412 - val_mae: 1.5412 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4104 - mae: 1.4104 - val_loss: 1.5303 - val_mae: 1.5303 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4069 - mae: 1.4069 - val_loss: 1.5931 - val_mae: 1.5931 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4104 - mae: 1.4104 - val_loss: 1.5311 - val_mae: 1.5311 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4080 - mae: 1.4080 - val_loss: 1.5365 - val_mae: 1.5365 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4262 - mae: 1.4262 - val_loss: 1.5561 - val_mae: 1.5561 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4119 - mae: 1.4119 - val_loss: 1.5472 - val_mae: 1.5472 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4221 - mae: 1.4221 - val_loss: 1.6292 - val_mae: 1.6292 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4545 - mae: 1.4545 - val_loss: 1.5337 - val_mae: 1.5337 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4392 - mae: 1.4392 - val_loss: 1.5801 - val_mae: 1.5801 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4056 - mae: 1.4056 - val_loss: 1.5873 - val_mae: 1.5873 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4267 - mae: 1.4267 - val_loss: 1.5659 - val_mae: 1.5659 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4368 - mae: 1.4368 - val_loss: 1.5343 - val_mae: 1.5343 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4343 - mae: 1.4343 - val_loss: 1.5530 - val_mae: 1.5530 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4256 - mae: 1.4256 - val_loss: 1.5654 - val_mae: 1.5654 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4159 - mae: 1.4159 - val_loss: 1.5684 - val_mae: 1.5684 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3983 - mae: 1.3983 - val_loss: 1.5549 - val_mae: 1.5549 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4325 - mae: 1.4325 - val_loss: 1.5566 - val_mae: 1.5566 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4087 - mae: 1.4087 - val_loss: 1.5495 - val_mae: 1.5495 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4031 - mae: 1.4031 - val_loss: 1.5540 - val_mae: 1.5540 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4070 - mae: 1.4070 - val_loss: 1.5646 - val_mae: 1.5646 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4233 - mae: 1.4233 - val_loss: 1.5309 - val_mae: 1.5309 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4188 - mae: 1.4188 - val_loss: 1.5281 - val_mae: 1.5281 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3972 - mae: 1.3972 - val_loss: 1.5303 - val_mae: 1.5303 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4393 - mae: 1.4393 - val_loss: 1.6037 - val_mae: 1.6037 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3930 - mae: 1.3930 - val_loss: 1.5592 - val_mae: 1.5592 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4139 - mae: 1.4139 - val_loss: 1.5391 - val_mae: 1.5391 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4506 - mae: 1.4506 - val_loss: 1.5518 - val_mae: 1.5518 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3980 - mae: 1.3980 - val_loss: 1.5890 - val_mae: 1.5890 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4167 - mae: 1.4167 - val_loss: 1.5605 - val_mae: 1.5605 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4199 - mae: 1.4199 - val_loss: 1.5294 - val_mae: 1.5294 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4220 - mae: 1.4220 - val_loss: 1.5560 - val_mae: 1.5560 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3929 - mae: 1.3929 - val_loss: 1.5305 - val_mae: 1.5305 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4281 - mae: 1.4281 - val_loss: 1.5420 - val_mae: 1.5420 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4268 - mae: 1.4268 - val_loss: 1.6039 - val_mae: 1.6039 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4189 - mae: 1.4189 - val_loss: 1.5357 - val_mae: 1.5357 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4163 - mae: 1.4163 - val_loss: 1.5354 - val_mae: 1.5354 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4138 - mae: 1.4138 - val_loss: 1.6016 - val_mae: 1.6016 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4040 - mae: 1.4040 - val_loss: 1.5864 - val_mae: 1.5864 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4172 - mae: 1.4172 - val_loss: 1.5417 - val_mae: 1.5417 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3986 - mae: 1.3986 - val_loss: 1.5378 - val_mae: 1.5378 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4091 - mae: 1.4091 - val_loss: 1.5503 - val_mae: 1.5503 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4184 - mae: 1.4184 - val_loss: 1.5633 - val_mae: 1.5633 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4207 - mae: 1.4207 - val_loss: 1.5418 - val_mae: 1.5418 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4142 - mae: 1.4142 - val_loss: 1.5603 - val_mae: 1.5603 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4254 - mae: 1.4254 - val_loss: 1.5433 - val_mae: 1.5433 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3882 - mae: 1.3882 - val_loss: 1.5381 - val_mae: 1.5381 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.4110 - mae: 1.4110 - val_loss: 1.5236 - val_mae: 1.5236 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4270 - mae: 1.4270 - val_loss: 1.5415 - val_mae: 1.5415 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4281 - mae: 1.4281 - val_loss: 1.5470 - val_mae: 1.5470 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3858 - mae: 1.3858 - val_loss: 1.5970 - val_mae: 1.5970 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4362 - mae: 1.4362 - val_loss: 1.5503 - val_mae: 1.5503 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3831 - mae: 1.3831 - val_loss: 1.5491 - val_mae: 1.5491 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4157 - mae: 1.4157 - val_loss: 1.5765 - val_mae: 1.5765 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4176 - mae: 1.4176 - val_loss: 1.5738 - val_mae: 1.5738 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3846 - mae: 1.3846 - val_loss: 1.5400 - val_mae: 1.5400 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4047 - mae: 1.4047 - val_loss: 1.5547 - val_mae: 1.5547 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4250 - mae: 1.4250 - val_loss: 1.5713 - val_mae: 1.5713 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4087 - mae: 1.4087 - val_loss: 1.5366 - val_mae: 1.5366 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3979 - mae: 1.3979 - val_loss: 1.5312 - val_mae: 1.5312 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4056 - mae: 1.4056 - val_loss: 1.5494 - val_mae: 1.5494 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4031 - mae: 1.4031 - val_loss: 1.5974 - val_mae: 1.5974 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3944 - mae: 1.3944 - val_loss: 1.5814 - val_mae: 1.5814 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4202 - mae: 1.4202 - val_loss: 1.5435 - val_mae: 1.5435 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3968 - mae: 1.3968 - val_loss: 1.5347 - val_mae: 1.5347 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4101 - mae: 1.4101 - val_loss: 1.5318 - val_mae: 1.5318 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4178 - mae: 1.4178 - val_loss: 1.5823 - val_mae: 1.5823 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4019 - mae: 1.4019 - val_loss: 1.5978 - val_mae: 1.5978 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3827 - mae: 1.3827 - val_loss: 1.5538 - val_mae: 1.5538 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3970 - mae: 1.3970 - val_loss: 1.5337 - val_mae: 1.5337 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3853 - mae: 1.3853 - val_loss: 1.5506 - val_mae: 1.5506 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4053 - mae: 1.4053 - val_loss: 1.5428 - val_mae: 1.5428 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3853 - mae: 1.3853 - val_loss: 1.5370 - val_mae: 1.5370 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3996 - mae: 1.3996 - val_loss: 1.5534 - val_mae: 1.5534 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3944 - mae: 1.3944 - val_loss: 1.5614 - val_mae: 1.5614 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3819 - mae: 1.3819 - val_loss: 1.5674 - val_mae: 1.5674 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.3748 - mae: 1.3748 - val_loss: 1.5461 - val_mae: 1.5461 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4174 - mae: 1.4174 - val_loss: 1.5609 - val_mae: 1.5609 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3848 - mae: 1.3848 - val_loss: 1.5412 - val_mae: 1.5412 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3964 - mae: 1.3964 - val_loss: 1.5744 - val_mae: 1.5744 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4070 - mae: 1.4070 - val_loss: 1.5896 - val_mae: 1.5896 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3881 - mae: 1.3881 - val_loss: 1.6081 - val_mae: 1.6081 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4189 - mae: 1.4189 - val_loss: 1.5492 - val_mae: 1.5492 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4068 - mae: 1.4068 - val_loss: 1.5585 - val_mae: 1.5585 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4052 - mae: 1.4052 - val_loss: 1.5574 - val_mae: 1.5574 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3859 - mae: 1.3859 - val_loss: 1.5385 - val_mae: 1.5385 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3805 - mae: 1.3805 - val_loss: 1.5496 - val_mae: 1.5496 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3979 - mae: 1.3979 - val_loss: 1.5259 - val_mae: 1.5259 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3820 - mae: 1.3820 - val_loss: 1.5335 - val_mae: 1.5335 - lr: 2.0000e-04\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3957 - mae: 1.3957 - val_loss: 1.5317 - val_mae: 1.5317 - lr: 2.0000e-04\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3898 - mae: 1.3898 - val_loss: 1.5412 - val_mae: 1.5412 - lr: 2.0000e-04\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3577 - mae: 1.3577 - val_loss: 1.5311 - val_mae: 1.5311 - lr: 2.0000e-04\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3748 - mae: 1.3748 - val_loss: 1.5377 - val_mae: 1.5377 - lr: 2.0000e-04\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3677 - mae: 1.3677 - val_loss: 1.5294 - val_mae: 1.5294 - lr: 2.0000e-04\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3814 - mae: 1.3814 - val_loss: 1.5364 - val_mae: 1.5364 - lr: 2.0000e-04\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3785 - mae: 1.3785 - val_loss: 1.5351 - val_mae: 1.5351 - lr: 2.0000e-04\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3623 - mae: 1.3623 - val_loss: 1.5363 - val_mae: 1.5363 - lr: 2.0000e-04\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3709 - mae: 1.3709 - val_loss: 1.5489 - val_mae: 1.5489 - lr: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2918be5da88>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(train_X, train_y, validation_split=0.3, epochs=1000, batch_size=32, verbose=1, callbacks=[es, cp, rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6cde187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6787fba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.098623 , 15.096386 ,  5.2617126, ...,  9.307539 ,  8.53819  ,\n",
       "       11.744217 ], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf79e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>2920</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>2921</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>2922</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>2923</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>2924</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Target\n",
       "0        1    10.0\n",
       "1        2    15.0\n",
       "2        3     5.0\n",
       "3        4    11.0\n",
       "4        5     9.0\n",
       "...    ...     ...\n",
       "2919  2920     4.0\n",
       "2920  2921     7.0\n",
       "2921  2922     9.0\n",
       "2922  2923     8.0\n",
       "2923  2924    11.0\n",
       "\n",
       "[2924 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "submission['Target'] = np.round(Y_prediction)\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdbaf0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./result/elu.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45dac07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
